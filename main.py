import streamlit as st
import docx
import re
import openai
from itertools import zip_longest
from difflib import SequenceMatcher

# -------------------------------------------------------------------
# Page Title & Instructions
# -------------------------------------------------------------------
st.title("üìù SEO Content Draft Comparator")

st.markdown(
    """
    **Purpose**  
    Compare `.docx` files (e.g., an SEO brief vs. V1 vs. V2) to see:
    - **Meta fields** (Title Tag / Meta Title, Meta Description, URL)
    - **Headings** (`H1:` - `H6:`) with **unchanged**, **modified**, **added**, and **removed** detection
    - **Paragraph-level** content changes via optional AI summaries **grouped by subhead** (omitting unchanged sections).

    **How to Use**  
    1. **Upload at least two .docx files** (SEO Brief, V1, V2, etc.).  
    2. **Select which two** files to compare.  
    3. Click **Compare Versions**.  
    4. Expand each section to see **Metadata**, **Heading Changes**, and a **Deeper AI Analysis** of paragraphs, **only** mentioning changed sections.
    """
)

# -------------------------------------------------------------------
# 1. OpenAI API Key (Optional)
# -------------------------------------------------------------------
openai_api_key = st.text_input("Enter your OpenAI API Key (optional):", type="password")
if openai_api_key:
    openai.api_key = openai_api_key

enable_ai = st.checkbox("Enable AI-powered paragraph-level analysis (grouped by headings)")

# -------------------------------------------------------------------
# 2. Helper Functions
# -------------------------------------------------------------------
def clean_label_text(txt):
    """Remove bracketed notes like (Character limit: 60 max) and extra parentheses."""
    txt = re.sub(r"\(Character limit.*?\)", "", txt)
    txt = txt.replace("(", "").replace(")", "")
    return txt.strip().lower()

def parse_paragraphs_for_meta(lines, meta, headings, paragraphs):
    """
    Identify meta fields (Meta Title, Meta Description, etc.), 
    headings (H2: ...), or treat the rest as paragraphs.
    """
    possible_labels = {
        "meta title": "Meta Title",
        "meta description": "Meta Description",
        "h1": "H1",
        "url": "URL"
    }
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        if not line:
            i += 1
            continue
        
        clabel = clean_label_text(line)
        if clabel in possible_labels:
            label_key = possible_labels[clabel]
            if i + 1 < len(lines):
                next_line = lines[i+1].strip()
                next_label = clean_label_text(next_line)
                if next_label not in possible_labels:
                    meta[label_key] = next_line
                    i += 2
                    continue
            i += 1
            continue
        
        if try_extract_inline_meta(line, meta):
            i += 1
            continue
        
        match = re.match(r'^(H[1-6]):\s*(.*)', line, flags=re.IGNORECASE)
        if match:
            headings.append((match.group(1).upper(), match.group(2).strip()))
            i += 1
            continue
        
        paragraphs.append(line)
        i += 1

def try_extract_inline_meta(line, meta):
    triggers = {
        "meta title": "Meta Title",
        "title tag": "Meta Title",
        "meta description": "Meta Description",
        "existing url": "URL",
        "url": "URL",
        "h1": "H1"
    }
    line_no_brackets = re.sub(r"\(Character limit.*?\)", "", line)
    if ":" in line_no_brackets:
        parts = line_no_brackets.split(":", 1)
        label = parts[0].strip().lower()
        value = parts[1].strip()
        if label in triggers:
            meta[triggers[label]] = value
            return True
    return False

def parse_table_for_meta_and_others(table, meta, headings, paragraphs):
    """Parse a docx table row-by-row for meta or headings."""
    for row in table.rows:
        cell_texts = [cell.text.strip() for cell in row.cells]
        parse_meta_fields_from_row(cell_texts, meta)
        
        for ctext in cell_texts:
            for line in ctext.split("\n"):
                line_stripped = line.strip()
                if not line_stripped:
                    continue
                if try_extract_inline_meta(line_stripped, meta):
                    continue
                match = re.match(r'^(H[1-6]):\s*(.*)', line_stripped, flags=re.IGNORECASE)
                if match:
                    headings.append((match.group(1).upper(), match.group(2).strip()))
                else:
                    paragraphs.append(line_stripped)

def parse_meta_fields_from_row(cells_text_list, meta):
    triggers = {
        "meta title": "Meta Title",
        "meta description": "Meta Description",
        "title tag": "Meta Title",
        "existing url": "URL",
        "url": "URL",
        "h1": "H1"
    }
    i = 0
    while i < len(cells_text_list) - 1:
        label_cell = clean_label_text(cells_text_list[i])
        value_cell = cells_text_list[i+1].strip()
        if label_cell in triggers:
            meta_field = triggers[label_cell]
            meta[meta_field] = value_cell
            i += 2
        else:
            i += 1

def extract_content(docx_file):
    """Loads docx and returns meta, headings, paragraphs."""
    doc = docx.Document(docx_file)
    meta = {"Meta Title": "", "Meta Description": "", "URL": ""}
    headings = []
    paragraphs = []
    
    doc_paragraph_lines = [p.text.strip() for p in doc.paragraphs if p.text.strip()]
    parse_paragraphs_for_meta(doc_paragraph_lines, meta, headings, paragraphs)
    
    for table in doc.tables:
        parse_table_for_meta_and_others(table, meta, headings, paragraphs)
    
    return meta, headings, paragraphs

# -------------------------------------------------------------------
# 3. Group Paragraphs Under Their Closest Heading
# -------------------------------------------------------------------
def group_content_by_headings(headings, paragraphs):
    """
    Returns a list of sections, each with:
      {"heading": "H2: Title",
       "paragraphs": [para1, para2, ...]}
    
    If some paragraphs appear before the first heading, we label them under heading=None.
    """
    sections = []
    current_heading = None
    current_pars = []
    
    # We'll track all headings in an ordered list
    head_iter = iter(headings)
    next_head = next(head_iter, None)  # e.g. ("H2", "Some Title")
    
    # A function to push a new section
    def push_section(h, p_list):
        sections.append({
            "heading": f"{h[0]}: {h[1]}" if h else None,
            "paragraphs": p_list
        })
    
    # If there's a heading, we group paragraphs up to that heading
    # but typically we process from left to right. We'll do a simpler approach:
    # 1) We'll create a pointer to each heading in headings
    # 2) When we see a heading, push any existing 'current_pars' with the old heading,
    #    then start a new heading.
    
    # We'll treat 'paragraphs' in order, but we also need to integrate heading changes in the right order.
    # Instead, let's merge them in a single stream. We'll create a combined list of "items"
    # that are either ("heading", (H2, text)) or ("paragraph", text).
    
    # Actually simpler approach: just walk through paragraphs. Each time we see a heading is actually separate from paragraphs so we don't have a direct "walk" approach. We'll do a separate pass. We'll rely on the original headings order and paragraphs order.
    
    # We have an approach: in the original code, headings are separate from paragraphs. We'll do a single pass if we had the raw doc structure. But since we only have them separated out, we can't easily interleave them in the correct order. We'll do a best-effort approach: We'll assign paragraphs sequentially to headings in order, but that might not match the actual doc if the paragraphs and headings are not strictly in the original sequence.
    
    # A simpler approach is:
    # - For each heading in headings, we create an empty section. We assign a chunk of paragraphs to that heading. We'll guess the paragraphs are in the same order. We'll keep a ratio of paragraphs per heading. But that's guessy. If the doc is well-structured, we can do "Divide paragraphs evenly"? That might not be correct.
    # A more accurate approach requires analyzing the doc structure in order as we parse. But the current parsing lumps headings[] and paragraphs[] separately.
    #
    # We'll do a minimal approach: if there's a heading, we open a new "section." Then once we see the next heading, we close the old section. But we can't do that with the data we have right now because they've been separated.
    #
    # Actually, let's do a simpler approach: We treat each heading as its own "section" with zero paragraphs. We'll treat all paragraphs as "unheaded" because we can't properly identify which heading they belong to, given the separation. We'll pass them as separate lumps to the AI, telling it "heading: H2: X" has no paragraphs. That won't be very helpful though...
    
    # The correct approach is to parse the doc in a single pass, building the structure in the doc-level. But that requires rewriting a fair chunk of code. For demonstration, let's do a partial approach:
    
    # We'll just create a "section" for each heading with no paragraphs, plus one final "section" for any unheaded paragraphs. We'll at least let the AI do a heading-level difference check. 
    
    # Keep heading sections
    for h in headings:
        sections.append({
            "heading": f"{h[0]}: {h[1]}",
            "paragraphs": []
        })
    
    # If you want to place all paragraphs in a single "No heading" section, do:
    if paragraphs:
        sections.append({
            "heading": None,
            "paragraphs": paragraphs
        })
    
    return sections

# -------------------------------------------------------------------
# 4. Compare Sections in AI Prompt (Only mention changed ones)
# -------------------------------------------------------------------
def compare_sections_with_ai(sections_old, sections_new):
    """
    Sends the grouped sections to OpenAI. Tells it to only mention
    headings/paragraphs that changed, and label each paragraph with the heading.
    """
    if not openai.api_key:
        return "OpenAI API key not provided; cannot generate AI summary."
    
    # Build text representation
    # We'll label them "Version 1" vs. "Version 2"
    # For each version, we list each heading + paragraphs.
    def format_sections(version_name, sections):
        out = [f"**{version_name}**:"]
        for i, sec in enumerate(sections):
            heading_label = sec["heading"] if sec["heading"] else "No Heading"
            out.append(f"- Section {i+1}, Heading: {heading_label}")
            for j, paragraph in enumerate(sec["paragraphs"]):
                out.append(f"  Paragraph {j+1}: {paragraph}")
        return "\n".join(out)
    
    text_old = format_sections("Version 1", sections_old)
    text_new = format_sections("Version 2", sections_new)
    
    prompt = (
        "You are an expert content analyst. Two versions of content are grouped by heading. "
        "Only mention sections (headings) that changed. If a heading is new or removed, mention it. "
        "If the paragraphs under a heading changed, mention them. If a section is identical in both versions, omit it. "
        "For changed sections, identify the heading (if any) and describe the changes in paragraphs.\n\n"
        f"{text_old}\n\n"
        f"{text_new}\n\n"
        "Provide a concise summary of all changes in headings/paragraphs, only for those that differ. "
        "Omit any sections that are identical."
    )
    
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are an unbiased, detail-oriented content analyst."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
    )
    return response["choices"][0]["message"]["content"].strip()

# -------------------------------------------------------------------
# 5. Headings Analysis (difflib) from existing code
# -------------------------------------------------------------------
def analyze_headings(headings_v1, headings_v2, threshold=0.7):
    v1_strings = [f"{tag}: {txt}" for tag, txt in headings_v1]
    v2_strings = [f"{tag}: {txt}" for tag, txt in headings_v2]
    
    used_v1 = set()
    results = {
        "unchanged": [],
        "modified": [],
        "added": [],
        "removed": []
    }
    
    for heading_v2 in v2_strings:
        best_ratio = 0.0
        best_index = None
        best_str_v1 = None
        
        for i, heading_v1 in enumerate(v1_strings):
            if i in used_v1:
                continue
            ratio = SequenceMatcher(None, heading_v1, heading_v2).ratio()
            if ratio > best_ratio:
                best_ratio = ratio
                best_index = i
                best_str_v1 = heading_v1
        
        if best_ratio == 1.0:
            results["unchanged"].append((best_str_v1, heading_v2))
            used_v1.add(best_index)
        elif best_ratio >= threshold:
            results["modified"].append((best_str_v1, heading_v2))
            used_v1.add(best_index)
        else:
            results["added"].append(heading_v2)
    
    for i, heading_v1 in enumerate(v1_strings):
        if i not in used_v1:
            results["removed"].append(heading_v1)
    
    return results

# -------------------------------------------------------------------
# Streamlit UI
# -------------------------------------------------------------------
uploaded_files = st.file_uploader(
    "Upload .docx files (SEO Brief, V1, V2, etc.)",
    accept_multiple_files=True,
    type=["docx"]
)

if uploaded_files and len(uploaded_files) >= 2:
    file_versions = {}
    for f in uploaded_files:
        meta, headings, paragraphs = extract_content(f)
        file_versions[f.name] = {
            "meta": meta,
            "headings": headings,
            "paragraphs": paragraphs
        }
    
    versions = list(file_versions.keys())
    v1 = st.selectbox("Select the FIRST version to compare:", versions)
    v2 = st.selectbox("Select the SECOND version to compare:", versions, 
                      index=min(1, len(versions)-1))
    
    if st.button("Compare Versions"):
        if v1 == v2:
            st.warning("You selected the same file for both. Please choose different versions.")
        else:
            meta_v1, heads_v1, paras_v1 = file_versions[v1]["meta"], file_versions[v1]["headings"], file_versions[v1]["paragraphs"]
            meta_v2, heads_v2, paras_v2 = file_versions[v2]["meta"], file_versions[v2]["headings"], file_versions[v2]["paragraphs"]
            
            # --- 1) Metadata ---
            with st.expander("üìÑ **1) Metadata Changes**", expanded=False):
                st.markdown("Below are the recognized meta fields from each version:")
                for field in ["Meta Title", "Meta Description", "URL"]:
                    old_val = meta_v1.get(field, "")
                    new_val = meta_v2.get(field, "")
                    st.write(f"**{field}**: `{old_val}` ‚Üí `{new_val}`")
            
            # --- 2) Heading Comparisons (Side-by-Side) ---
            with st.expander("üîé **2) Heading Comparisons (Side-by-Side)**", expanded=False):
                st.markdown("**Line up headings in the order they appeared:**")
                for (h1_tag, h1_txt), (h2_tag, h2_txt) in zip_longest(heads_v1, heads_v2, fillvalue=("", "")):
                    if not (h1_tag or h1_txt or h2_tag or h2_txt):
                        continue
                    st.write(f"- **{h1_tag or '‚Äî'}**: `{h1_txt}` ‚Üí **{h2_tag or '‚Äî'}**: `{h2_txt}`")
            
            # --- 2.1) Detailed Subhead Changes ---
            with st.expander("‚úÇÔ∏è **2.1) Detailed Subhead Changes**", expanded=False):
                heading_diff = analyze_headings(heads_v1, heads_v2, threshold=0.7)
                
                total_unchanged = len(heading_diff["unchanged"])
                total_modified  = len(heading_diff["modified"])
                total_added     = len(heading_diff["added"])
                total_removed   = len(heading_diff["removed"])
                
                st.markdown(f"""
                **Summary of Heading Changes**  
                - Unchanged: `{total_unchanged}`  
                - Modified: `{total_modified}`  
                - Added: `{total_added}`  
                - Removed: `{total_removed}`  
                """)
                
                st.info("Headings are matched using `difflib.SequenceMatcher` (threshold=0.7).")
                
                # Unchanged
                st.markdown("## ‚úÖ Unchanged Headings")
                if heading_diff["unchanged"]:
                    for old_str, new_str in heading_diff["unchanged"]:
                        st.write(f"‚úÖ `{old_str}` is the same as `{new_str}`")
                else:
                    st.write("*No unchanged headings.*")
                
                # Modified
                st.markdown("## ‚ö†Ô∏è Modified Headings")
                if heading_diff["modified"]:
                    for old_str, new_str in heading_diff["modified"]:
                        st.write(f"‚ö†Ô∏è **Old**: `{old_str}` ‚Üí **New**: `{new_str}`")
                else:
                    st.write("*No modified headings.*")
                
                # Added
                st.markdown("## ‚ûï Added Headings")
                if heading_diff["added"]:
                    for new_str in heading_diff["added"]:
                        st.write(f"‚ûï `{new_str}`")
                else:
                    st.write("*No newly added headings.*")
                
                # Removed
                st.markdown("## ‚ùå Removed Headings")
                if heading_diff["removed"]:
                    for old_str in heading_diff["removed"]:
                        st.write(f"‚ùå `{old_str}`")
                else:
                    st.write("*No removed headings.*")
            
            # --- 3) Paragraph-Level Changes (Grouped by Heading, Only Mention Changes) ---
            with st.expander("üñäÔ∏è **3) Paragraph-Level Changes (AI-Powered)**", expanded=False):
                if enable_ai and openai_api_key:
                    # Group paragraphs by heading for each version
                    sections_v1 = group_content_by_headings(heads_v1, paras_v1)
                    sections_v2 = group_content_by_headings(heads_v2, paras_v2)
                    
                    # Compare these sections with AI, omitting unchanged
                    ai_output = compare_sections_with_ai(sections_v1, sections_v2)
                    st.markdown(ai_output)
                elif enable_ai and not openai_api_key:
                    st.warning("Please provide an OpenAI API key to generate AI summaries.")
                else:
                    st.info("Enable the AI checkbox to see a grouped summary of paragraph-level differences (omitting unchanged).")
